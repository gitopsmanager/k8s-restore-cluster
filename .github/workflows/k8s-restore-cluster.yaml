name: Restore Cluster and Deploy ArgoCD (Matrix + Aggregation)

on:
  workflow_call:
    inputs:
      github_runner:
        required: true
        type: string
      cluster_restore_source:
        description: "Optional: Source cluster directory name"
        required: false
        default: ""
        type: string
      cluster_restore_target:
        description: "Target cluster directory name (required)"
        required: true
        type: string
      namespace_filter:
        description: >
          Optional comma-separated list of namespaces or namespace:app pairs
          (e.g. 'prod,qa:web')
        required: false
        default: ""
        type: string
      cd_repo_org:
        description: "GitHub org/owner of continuous-deployment repo"
        required: true
        type: string
      cd_repo:
        description: "Continuous-deployment repository name"
        required: true
        type: string
      insecure_argo:
        required: false
        default: false
        type: boolean
      delete_first:
        required: false
        default: false
        type: boolean
      delete_only:
        required: false
        default: false
        type: boolean
      skip_status_check:
        required: false
        default: false
        type: boolean

      backfill_create_json:
        description: >
          If true, regenerate missing create.json files for all applications
          currently deployed in the target ArgoCD cluster. This ensures the
          continuous-deployment repository is complete and ready for future
          cluster restore operations.
        required: false
        default: false
        type: boolean



    secrets:
      # --- ArgoCD Authentication (Provide one or the other) ---
      ARGOCD_AUTH_TOKEN:
        description: "ArgoCD API authentication token. Provide this OR username/password."
        required: false
      ARGOCD_USERNAME:
        description: "ArgoCD username (used if token not set). Provide this with ARGOCD_PASSWORD."
        required: false
      ARGOCD_PASSWORD:
        description: "ArgoCD password (used if token not set). Provide this with ARGOCD_USERNAME."
        required: false
      ARGOCD_CA_CERT:
        description: "Optional custom CA certificate for ArgoCD."
        required: false

      # --- GitHub App Secrets (always required) ---
      CONTINUOUS_DEPLOYMENT_GH_APP_ID:
        description: "GitHub App ID with write access to the CD repo."
        required: true
      CONTINUOUS_DEPLOYMENT_GH_APP_PRIVATE_KEY:
        description: "GitHub App private key for token generation."
        required: true



jobs:
  restore:
    runs-on: ${{ inputs.github_runner }}
    outputs:
      matrix: ${{ steps.build.outputs.matrix }}
    steps:
      - uses: actions/checkout@v4

      - name: Generate GitHub App token
        id: generate_token
        uses: actions/create-github-app-token@v2
        with:
          app-id: ${{ secrets.CONTINUOUS_DEPLOYMENT_GH_APP_ID }}
          private-key: ${{ secrets.CONTINUOUS_DEPLOYMENT_GH_APP_PRIVATE_KEY }}
          owner: ${{ inputs.cd_repo_org }}
          repositories: ${{ inputs.cd_repo }}


      - name: Checkout continuous-deployment repo
        uses: actions/checkout@v4
        with:
          repository: ${{ inputs.cd_repo_org }}/${{ inputs.cd_repo }}
          token: ${{ steps.generate_token.outputs.token }}
          path: continuous-deployment

      - name: Import ENV_MAP from runner
        shell: bash
        run: |
          printf "ENV_MAP<<EOF\n%s\nEOF\n" "$ENV_MAP" >> $GITHUB_ENV


      # --- Load source environment (if provided) ---
      - name: Load Source Environment Config
        if: ${{ inputs.cluster_restore_source != '' }}
        id: env_src
        uses: gitopsmanager/k8s-load-env@v1
        env:
          ENV_MAP: ${{ env.ENV_MAP }}
        with:
          env_map: ${{ inputs.env_map }}
          target_environment: ${{ inputs.target_environment }}
          target_cluster: ${{ inputs.cluster_restore_source }}
          namespace: ${{ inputs.namespace }}

      # --- Load target environment (always required) ---
      - name: Load Target Environment Config
        id: env_tgt
        uses: gitopsmanager/k8s-load-env@v1
        env:
          ENV_MAP: ${{ env.ENV_MAP }}
        with:
          env_map: ${{ inputs.env_map }}
          target_environment: ${{ inputs.target_environment }}
          target_cluster: ${{ inputs.cluster_restore_target }}
          namespace: ${{ inputs.namespace }}

      # --- Debug env outputs ---
      - name: Debug env outputs
        run: |
          echo "source_cluster='${{ steps.env_src.outputs.cluster }}'"
          echo "source_dns_zone='${{ steps.env_src.outputs.dns_zone }}'"
          echo "target_cluster='${{ steps.env_tgt.outputs.cluster }}'"
          echo "target_dns_zone='${{ steps.env_tgt.outputs.dns_zone }}'"



      - name: Backfill create.json for cluster
        id: list  # âœ… Added ID so outputs can be used below
        uses: gitopsmanager/ArgoCD-Manage-Applications@v1
        with:
          list_only: "true"
          argocd_url:          https://${{ steps.env_tgt.outputs.cluster }}-argocd-argocd-web-ui.${{ steps.env_tgt.outputs.dns_zone }}
          argocd_auth_token:   ${{ secrets.ARGOCD_AUTH_TOKEN }}
          argocd_username:     ${{ secrets.ARGOCD_USERNAME }}
          argocd_password:     ${{ secrets.ARGOCD_PASSWORD }}
          insecure_argo:       ${{ inputs.insecure_argo }}
          argocd_ca_cert:      ${{ secrets.ARGOCD_CA_CERT }}
          namespace:           default
          cd_repo:             ${{ inputs.cd_repo }}
          cd_repo_org:         ${{ inputs.cd_repo_org }}
          cd_path_rel:         dummy
          apps:                "[]"


      - name: Generate and print missing create.json files
        if: ${{ inputs.backfill_create_json }}
        id: backfill_create
        uses: actions/github-script@v7
        env:
          CLUSTER_TARGET: ${{ inputs.cluster_restore_target }}
          JSON_FILE: ${{ steps.list.outputs.json_file }}
          CD_REPO: continuous-deployment
          CD_REPO_ORG: ${{ inputs.cd_repo_org }}
          CD_REPO_NAME: ${{ inputs.cd_repo }}
        with:
          script: |
            const fs = require("fs");
            const path = require("path");

            const cluster = process.env.CLUSTER_TARGET;
            const repo = `${process.env.CD_REPO_ORG}/${process.env.CD_REPO_NAME}`;
            const baseDir = path.join(process.env.GITHUB_WORKSPACE, process.env.CD_REPO, cluster);
            const jsonFile = process.env.JSON_FILE;

            if (!fs.existsSync(jsonFile)) {
              core.setFailed(`âŒ ArgoCD applications file not found: ${jsonFile}`);
              return;
            }

            const appsJson = fs.readFileSync(jsonFile, "utf8");
            let apps;
            try {
              const parsed = JSON.parse(appsJson);
              apps = parsed.items || [];
            } catch (err) {
              core.setFailed("âŒ Failed to parse ArgoCD applications JSON: " + err.message);
              return;
            }

            core.info(`ðŸ“‹ Simulating backfill for cluster '${cluster}' (${apps.length} apps)...`);

            let created = 0;
            for (const app of apps) {
              const ns = app?.spec?.destination?.namespace || "default";
              const fullName = app?.metadata?.name || "unknown";
              const shortName = fullName.startsWith(`${ns}-`)
                ? fullName.substring(ns.length + 1)
                : fullName;

              const srcPath = app?.spec?.source?.path || "";

              // Derive overlay_dir and clean path
              let overlayDir = "";
              let cleanPath = srcPath;
              const overlayMatch = srcPath.match(/\/overlays\/([^/]+)/);
              if (overlayMatch) {
                overlayDir = overlayMatch[1];
                cleanPath = srcPath.replace(`/overlays/${overlayDir}`, "");
              }

              const relDir = path.join(baseDir, ns, shortName);
              const createJson = path.join(relDir, "create.json");

              if (fs.existsSync(createJson)) {
                core.info(`âœ… Exists, skipping: ${path.relative(".", createJson)}`);
                continue;
              }

              const jsonData = {
                cluster,
                namespace: ns,
                overlay_dir: overlayDir,
                applications: [
                  {
                    name: shortName,
                    repo
                  }
                ]
              };

              // --- Log preview to console ---
              core.startGroup(`ðŸ†• Creating: ${path.relative(".", createJson)}`);
              core.info(JSON.stringify(jsonData, null, 2));
              core.endGroup();

              // Uncomment to actually write files:
              fs.mkdirSync(relDir, { recursive: true });
              fs.writeFileSync(createJson, JSON.stringify(jsonData, null, 2), "utf8");

              created++;
            }

            if (created === 0) {
              core.info("â„¹ï¸ No new create.json files would be created.");
            } else {
              core.info(`âœ… ${created} create.json file(s) would be generated.`);
            }


      - name: Auto Commit and Squash Merge Backfill
        if: ${{ inputs.backfill_create_json }}
        uses: gitopsmanager/Auto-Commit-Squash-Merge@v1
        with:
          token: ${{ steps.generate_token.outputs.token }}
          repo_owner: ${{ inputs.cd_repo_org }}
          repo_name: ${{ inputs.cd_repo }}
          namespace: "cluster-backfill"
          cluster: ${{ inputs.cluster_restore_target }}
          app_name: "backfill-create-json"
          repo_path_rel: ${{ inputs.cluster_restore_target }}
          delete_only: false


      - name: Exit after backfill 
        if: ${{ inputs.backfill_create_json }}
        run: exit 0
        shell: bash


      # --- Validate and Restore Cluster ---
      - name: Validate and Restore Cluster
        id: restore
        run: |
          set -euo pipefail

          SRC="${{ inputs.cluster_restore_source }}"
          TGT="${{ inputs.cluster_restore_target }}"
          SRC_DIR="continuous-deployment/${SRC}"
          TGT_DIR="continuous-deployment/${TGT}"

          SRC_CLUSTER="${{ steps.env_src.outputs.cluster }}"
          TGT_CLUSTER="${{ steps.env_tgt.outputs.cluster }}"
          SRC_DNS_ZONE="${{ steps.env_src.outputs.dns_zone }}"
          TGT_DNS_ZONE="${{ steps.env_tgt.outputs.dns_zone }}"

          echo "ðŸ” Validating inputs..."
          if [ -n "$SRC" ]; then
            if [ ! -d "$SRC_DIR" ]; then
              echo "âŒ Source '$SRC_DIR' does not exist."
              exit 1
            fi
            if [ -d "$TGT_DIR" ]; then
              echo "âŒ Target '$TGT_DIR' already exists. Refusing to overwrite."
              exit 1
            fi

            echo "ðŸ“‚ Copying $SRC_DIR â†’ $TGT_DIR"
            cp -r "$SRC_DIR" "$TGT_DIR"

            echo "ðŸ”„ Replacing cluster name '${SRC_CLUSTER}' â†’ '${TGT_CLUSTER}'"
            find "$TGT_DIR" -type f -exec sed -i "s/${SRC_CLUSTER}/${TGT_CLUSTER}/g" {} +

            echo "ðŸŒ Replacing DNS zone '${SRC_DNS_ZONE}' â†’ '${TGT_DNS_ZONE}'"
            find "$TGT_DIR" -type f -exec sed -i "s/${SRC_DNS_ZONE}/${TGT_DNS_ZONE}/g" {} +

            echo "created=true" >> "$GITHUB_OUTPUT"
          else
            if [ ! -d "$TGT_DIR" ]; then
              echo "âŒ No source provided and target '$TGT_DIR' does not exist."
              exit 1
            fi
            echo "â„¹ï¸ No source provided. Using existing target cluster '$TGT_DIR'."
            echo "created=false" >> "$GITHUB_OUTPUT"
          fi

      # --- Fix UAMI client IDs in target manifests ---
      - name: Fix UAMI client IDs in target manifests
        if: ${{ inputs.cluster_restore_source != '' }}
        uses: actions/github-script@v7
        env:
          SRC_CLUSTER: ${{ steps.env_src.outputs.cluster }}
          TGT_CLUSTER: ${{ steps.env_tgt.outputs.cluster }}
          SRC_UAMI_VARS_B64: ${{ steps.env_src.outputs.uami_vars_b64 }}
          TGT_UAMI_VARS_B64: ${{ steps.env_tgt.outputs.uami_vars_b64 }}
          TGT_DIR: continuous-deployment/${{ inputs.cluster_restore_target }}
        with:
          script: |
            const fs = require("fs");
            const path = require("path");
            const { execSync } = require("child_process");

            function decode(b64) {
              try { return JSON.parse(Buffer.from(b64 || "", "base64").toString() || "{}"); }
              catch { return {}; }
            }

            const srcCluster = process.env.SRC_CLUSTER;
            const tgtCluster = process.env.TGT_CLUSTER;
            const baseDir = process.env.TGT_DIR;
            const srcUami = decode(process.env.SRC_UAMI_VARS_B64);
            const tgtUami = decode(process.env.TGT_UAMI_VARS_B64);

            core.info(`ðŸ” Scanning ${baseDir} for azure.workload.identity/client-id entries...`);

            // 1ï¸âƒ£ Find all YAML files that mention azure.workload.identity/client-id
            let files = [];
            try {
              const grep = execSync(`grep -rl "azure.workload.identity/client-id" "${baseDir}" || true`, { encoding: "utf8" });
              files = grep.split("\n").filter(Boolean);
            } catch {
              core.warning("âš ï¸ No files containing azure.workload.identity/client-id found.");
            }

            if (files.length === 0) {
              core.info("âœ… No UAMI references to update.");
              return;
            }

            core.info(`ðŸ“„ Found ${files.length} file(s) referencing azure.workload.identity/client-id`);
            for (const file of files) {
              let data = fs.readFileSync(file, "utf8");
              let updated = data;
              for (const [key, srcClientId] of Object.entries(srcUami)) {
                const baseKey = key.replace(`${srcCluster}-`, "");
                const tgtKey = `${tgtCluster}-${baseKey}`;
                const newClientId = tgtUami[tgtKey] || tgtUami[baseKey];
                if (!newClientId) continue;

                const regex = new RegExp(
                  `azure\\.workload\\.identity/client-id:\\s*${srcClientId}`,
                  "g"
                );
                updated = updated.replace(
                  regex,
                  `azure.workload.identity/client-id: ${newClientId}`
                );
              }
              if (updated !== data) {
                fs.writeFileSync(file, updated, "utf8");
                core.info(`ðŸ” Updated client IDs in ${file}`);
              }
            }
            core.info("âœ… Finished updating UAMI client IDs.");




      # --- Commit if new target created ---
      - name: Auto Commit and Squash Merge
        if: ${{ steps.restore.outputs.created == 'true' }}
        uses: gitopsmanager/Auto-Commit-Squash-Merge@v1
        with:
          token: ${{ steps.token.outputs.token }}
          repo_owner: ${{ inputs.cd_repo_org }}
          repo_name: ${{ inputs.cd_repo }}
          namespace: "cluster-restore"
          cluster: ${{ inputs.cluster_restore_target }}
          app_name: "restore"
          repo_path_rel: "continuous-deployment/${{ inputs.cluster_restore_target }}"
          delete_only: false

      # --- Build matrix from create.json ---
      - name: Build Matrix from create.json
        id: build
        uses: actions/github-script@v7
        env:
          CLUSTER_TARGET: ${{ inputs.cluster_restore_target }}
          FILTER: ${{ inputs.namespace_filter }}
          TARGET_DNS_ZONE: ${{ steps.env_tgt.outputs.dns_zone }}
        with:
          script: |
            const fs = require("fs");
            const path = require("path");

            const clusterDir = path.join("continuous-deployment", process.env.CLUSTER_TARGET);
            if (!fs.existsSync(clusterDir)) {
              core.setFailed(`âŒ Cluster directory not found: ${clusterDir}`);
              return;
            }

            const filters = (process.env.FILTER || "")
              .split(",")
              .map(s => s.trim())
              .filter(Boolean);

            // Recursively find all create.json files under the cluster directory
            const files = [];
            function walk(dir) {
              for (const e of fs.readdirSync(dir, { withFileTypes: true })) {
                const full = path.join(dir, e.name);
                if (e.isDirectory()) walk(full);
                else if (e.name === "create.json") files.push(full);
              }
            }
            walk(clusterDir);

            if (files.length === 0) {
              core.warning(`âš ï¸ No create.json found under ${clusterDir}`);
              core.setOutput("matrix", "[]");
              return;
            }

            const dnsZone = process.env.TARGET_DNS_ZONE;
            const matrix = [];

            for (const f of files) {
              const json = JSON.parse(fs.readFileSync(f, "utf8"));
              const ns = json.namespace || "";
              const overlay = json.overlay_dir || "";
              const cluster = json.cluster || process.env.CLUSTER_TARGET || "";
              const apps = json.applications || [];
              const application = json.application || json.app_name || "";

              // --- Build cd_path_rel from JSON contents, not from file path ---
              let cdPathRel = "";
              if (cluster && application) {
                cdPathRel = path.join(cluster, application);
              } else if (cluster && ns) {
                cdPathRel = path.join(cluster, ns); // fallback if app missing
              } else {
                core.warning(`âš ï¸ Could not determine cd_path_rel from ${f}`);
                continue;
              }

              // --- Optional sanity check ---
              const absPath = path.join("continuous-deployment", cdPathRel);
              if (!fs.existsSync(absPath)) {
                core.warning(`âš ï¸ Path ${absPath} does not exist (derived from ${f})`);
              }

              // --- Apply namespace/app filters ---
              const matchesNamespace = filters.includes(ns);
              const matchesApp = apps.some(a => filters.includes(`${ns}:${a.name}`));
              if (filters.length > 0 && !matchesNamespace && !matchesApp) {
                core.info(`â­ï¸ Skipping ${f} (not in filter)`);
                continue;
              }

              matrix.push({
                file: f,
                cd_path_rel: cdPathRel,
                namespace: ns,
                overlay_dir: overlay,
                cluster: cluster,
                dns_zone: dnsZone,
                apps: JSON.stringify(apps)
              });

              core.info(`ðŸ“¦ Added ${cdPathRel} from ${path.relative("continuous-deployment", f)}`);
            }

            core.info(`âœ… Found ${matrix.length} deployment(s)`);
            core.setOutput("matrix", JSON.stringify(matrix));


  deploy:
    needs: restore
    runs-on:  ${{ inputs.github_runner }}
    strategy:
      fail-fast: false
      max-parallel: 5
      matrix:
        include: ${{ fromJSON(needs.restore.outputs.matrix) }}

    steps:
      - uses: actions/checkout@v4

      - name: Construct ArgoCD URL
        id: build_argo_url
        run: |
          echo "url=https://${{ matrix.cluster }}-argocd-argocd-web-ui.${{ matrix.dns_zone }}" >> $GITHUB_OUTPUT

      - name: Manage ArgoCD Applications
        uses: gitopsmanager/ArgoCD-Manage-Applications@v1
        with:
          argocd_url:          ${{ steps.build_argo_url.outputs.url }}
          argocd_auth_token:   ${{ inputs.argocd_auth_token }}
          argocd_username:     ${{ secrets.ARGOCD_USERNAME }}
          argocd_password:     ${{ secrets.ARGOCD_PASSWORD }}
          insecure_argo:       ${{ inputs.insecure_argo }}
          argocd_ca_cert:      ${{ secrets.ARGOCD_CA_CERT }}
          namespace:           ${{ matrix.namespace }}
          cd_repo:             ${{ inputs.cd_repo }}
          cd_repo_org:         ${{ inputs.cd_repo_org }}
          cd_path_rel:         ${{ matrix.cd_path_rel }}
          overlay_dir:         ${{ matrix.overlay_dir }}
          apps:                ${{ matrix.apps }}
          delete_first:        ${{ inputs.delete_first }}
          delete_only:         ${{ inputs.delete_only }}
          skip_status_check:   ${{ inputs.skip_status_check }}


